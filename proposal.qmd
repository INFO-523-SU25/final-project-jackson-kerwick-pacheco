---
title: "Urbanization and Environmental Quality in Arizona, USA"
subtitle: "Proposal"
author: 
  - name: "JKP (Vera Jackson, Molly Kerwick, Brooke Pacheco)"
    affiliations:
      - name: "College of Information Science, University of Arizona"
description: "Final Project for course INFO 523: Data Mining and Discovery"
format:
  html:
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    embed-resources: true
editor: visual
code-annotations: hover
execute:
  warning: false
jupyter: python3
---

```{python}
#| label: load-pkgs
#| message: false
import numpy as np
import pandas as pd
import glob
```

The goal of our project is to analyze the relationship between urbanization and environmental quality across regions, identifying patterns and anomalies in how urban growth impacts climate-related factors such as storms, temperature, and drought

## Datasets

### Dataset 1 - Storm Data in Arizona 

```{python}
#| label: load-dataset
#| message: false

# Storm Events in Arizona

# Load csv file
df = pd.read_csv('data/StormEvents/storm_data_search_results.csv')

# Print using shape property
print("Shape:", df.shape)

# Print column names
print("Columns:", df.columns.tolist())

# Print data types of all of the columns
print("Data types:", df.dtypes)

# Print summary of the data
df.info()

```

This dataset contains storm event records in Arizona, sourced from the NOAA Storm Events Database. It includes information about various weather events such as floods, tornadoes, and severe storms, along with details like location, date, event type, magnitude, fatalities, injuries, and property damage. It also includes metadata such as time zones, county information, and narrative descriptions of each event.

The dataset consists of a mix of numerical and categorical values, specifically, 12 columns with integer types and 27 with object types. It was chosen for its relevance to climate and environmental analysis in Arizona. The data enables the exploration of temporal and spatial patterns in extreme weather events and supports investigations into trends related to climate change, urbanization, and risk assessment.

### Dataset 2 - Weather Data in Arizona 

```{python}

# NOAA Data

# reading in data and
file_location = "data/NOAA/"
all_files = glob.glob(file_location + "*.csv")

list_of_dfs = []

for file in all_files:
  df = pd.read_csv(file)
  list_of_dfs.append(df)

# merging data together into one data frame
noaadata = pd.concat(list_of_dfs, ignore_index = True)
```

```{python}

# glance at NOAA climate data

# Print using shape property
print("Shape:", noaadata.shape)

# Print column names
print("Columns:", noaadata.columns.tolist())

# Print data types of all of the columns
print("Data types:", noaadata.dtypes)

# Print summary of the data
noaadata.info()

noaadata.head()

```

This data from [NOAA National Centers for Environmental Information] (https://www.ncdc.noaa.gov/cdo-web/datasets) will serve as a measure of environmental quality. The dataset `noaadata` is a compilation of daily land surface observations within Arizona from 2018 to 2023. Some variables of importance includes latitude and longitude of station, temperatures, precipitation, and snowfall.

This data contains primarily numerical values, with the only categorical variables being the name of the station where weather data is collected, and date the data was collected.

### Dataset 3 - Traffic Data in Arizona 

```{python}

# Traffic data sourced from FHWA
# with aggregate station data over all months from 2019 to 2023. FWHA changed their data
# format in 2022, so the data are stored in two different formats

# storing each year of traffic data as a dictionary of pd.DataFrames
station_data = {}

for year in np.arange(2019,2024):
  df = pd.DataFrame()
  if (year < 2022):   
    # old data format
    fname = f'data/Traffic/stations/Station_Data_Extract_Pipe_Delimited_CleanData_{str(year)}.txt'
    df = pd.read_csv(fname, sep='|', low_memory=False)
    # For old format only, remove every entry where state_code != 04 (entries not in Arizona)
    df = df[(df['State_Code'] == 4)]
    df.columns = [x.lower() for x in df.columns]  # make columns lowercase like new data format
  else:
    # new data format
    df = pd.read_csv('data/Traffic/stations/AZ_2023 (TMAS).txt', sep='|')

  df = df.reset_index()
  station_data[year] = df


# Information about station dataset

print("Geographic locations of each station are formatted as follows:")
print(station_data[2019].columns)
print(station_data[2019].info())


# Traffic counts at each station are in files. All station and traffic data
# will be aggregated together into a dataframe where each row is a traffic
# count for each year for each county 

# data conversion tool https://github.com/policyinfo/TMAS-Traffic-Volume-Data-Rearrangement-Tool/blob/main/Tool_Document.pdf

traffic_files = []

for i in range(19, 23):
  year = "{:02}".format(i)
  for j in range(1,13):
    monthyear = "{:02}".format(j) + year
    fname = f"data/Traffic/counts/AZ{monthyear}.VOL"
    traffic_files.append(fname)

print("Counts of traffic stations will be read in from the following files:")
print(traffic_files)
```

```{python}

# As an example, here is traffic count data from a single month of a single year
df_count = pd.read_csv('data/Traffic/counts/AZ1019.VOL')
print(df_count.columns)
print(df_count.info())

# The following is an example of how we will combine hourly counts into a sum over each day

df_volumes = df_count.copy()
df_volumes['daily_volume'] = df_volumes[["Hour_{:02}".format(i) for i in range(24)]].sum(axis=1)
df_volumes = df_volumes.drop(["Hour_{:02}".format(i) for i in range(24)], axis=1)



```

The traffic data above is sourced from the Federal Highway Administration (FHWA) of the U.S. Department of Transportation (https://www.fhwa.dot.gov/policyinformation/tables/tmasdata/). It will serve as a metric for urbanization level of regions throughout Arizona. It is presumed that counties with higher traffic flow have greater urbanization than counties with low traffic flow. 

The traffic data are sourced from two different file structures, counts data and station data. Counts 


Make sure to load the data and use inline code for some of this information.)





To measure urbanization, we will use traffic volume as our metric.
To measure environmental quality, we will use climate data from NOAA.



## Questions

The two questions you want to answer.

1. Can we predict environmental quality of a region based on urbanization indicators for that region?
2. Are storm event data and traffic data successful environmental health and urbanization indicators, respectively?

## Analysis plan

-   We will identify the relationship between traffic data, the metric for urbanization, and weather and storm data, the metrics for environmental quality. We will do this with multivariate regression models.
-   We will conduct a PCA of the data by region to compare urbanized and rural areas.
